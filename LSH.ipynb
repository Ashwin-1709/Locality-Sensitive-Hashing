{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locality Sensitive Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from itertools import combinations\n",
    "root = Path(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_1 = pd.read_csv('articles1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsh_stats = {\n",
    "    'b' : list(),\n",
    "    'r' : list(),\n",
    "    'Number of hash functions' : list(),\n",
    "    'True Positive' : list(),\n",
    "    'True Negative' : list(),\n",
    "    'False Positive' : list(),\n",
    "    'False Negative' : list(),\n",
    "    'Candidate Pair count' : list()\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load the pickled documents into RAM. The first step of LSH is the creation of the signature matrix. Since incident matrix is too sparse and dimension heavy, we create a compact signature matrix using the minhashing technique. \n",
    "</br> </br>\n",
    "<span style=\"color:yellow\">get_hash_functions(hsh_cnt, mod)</span> generates hsh_cnt random hash functions which will be used for minhashing. The generated hash functions are of the form $(ax + b)$ % $mod$\n",
    "</br> </br>\n",
    "MinHashing Technique : \n",
    "</br>\n",
    "The signature matrix is created using the minhash technique where we apply all of the hash functions row-wise and update the minimum hash value in each document which has the current shingle.\n",
    "</br></br>\n",
    "The general idea of LSH is to find a algorithm such that if we input signatures of 2 documents, it tells us that those 2 documents form a candidate pair. The signature matrix is divided into b bands of r row each, for each band we hash its portion of the column in the corresponding bucket, Candidate column pairs are those that hash to the same bucket for at least 1 band. The results are verified by actually checking if those documents actually have similarity >= threshold. The top 3 similar documents, number of candidate pairs along with statistics depicting performance of LSH (True Positive, True Negative, False Positive, False Negative) is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSH:\n",
    "    def __init__(self, b, r, hash_cnt) -> None:\n",
    "        self.unpickle()\n",
    "        self.hash_functions = self.get_hash_functions(hash_cnt, len(self.incident_matrix))\n",
    "        self.min_hash()\n",
    "        self.make_candidate_pairs(b, r)\n",
    "\n",
    "    def get_hash_functions(self, hsh_cnt, mod): \n",
    "        hash_function = list()\n",
    "        for _ in range(hsh_cnt) : \n",
    "            a = random.randint(1, 100)\n",
    "            b = random.randint(1, 100)\n",
    "            hash_function.append((a, b, mod))\n",
    "        return hash_function\n",
    "\n",
    "    def min_hash(self):\n",
    "        self.signature_matrix = np.zeros(shape=(len(self.hash_functions), len(self.documents)))\n",
    "        self.signature_matrix.fill(10 ** 18)\n",
    "\n",
    "        for shingle_row in range(len(self.incident_matrix)): \n",
    "            cur_hsh = 0\n",
    "            shingle_row_val = np.array(self.incident_matrix[shingle_row])\n",
    "            ids_take = np.nonzero(shingle_row_val)\n",
    "            \n",
    "            for (a, b, mod) in self.hash_functions: \n",
    "                hsh_value = ((shingle_row + 1) * a + b) % mod\n",
    "\n",
    "                for doc_id in ids_take[0]:\n",
    "                    if shingle_row_val[doc_id] == 1:\n",
    "                        self.signature_matrix[cur_hsh][doc_id] = min(self.signature_matrix[cur_hsh][doc_id], hsh_value)\n",
    "                cur_hsh += 1\n",
    "\n",
    "        my_path = root / \"Pickled_files\" / \"Signature_Matrix\"\n",
    "        dbfile = open(my_path, 'wb')\n",
    "        pickle.dump(self.signature_matrix, dbfile) \n",
    "        dbfile.close()\n",
    "\n",
    "    def make_candidate_pairs(self, b, r): \n",
    "        self.candidate_pairs = set()\n",
    "        self.taken_candidate_pairs = np.zeros(shape=(len(self.documents), len(self.documents)))\n",
    "        cur_band_start, cur_band_end = 0, r - 1\n",
    "        for _ in range(b):\n",
    "            band_signature = dict() \n",
    "            for doc_id in range(len(self.documents)): \n",
    "                matrix = tuple(self.signature_matrix[cur_band_start : cur_band_end + 1, doc_id])\n",
    "                if band_signature.get(matrix) == None: \n",
    "                    band_signature[matrix] = [doc_id]\n",
    "                else: \n",
    "                    band_signature[matrix].append(doc_id)\n",
    "            for docs in band_signature.items(): \n",
    "                if len(docs[1]) > 1: \n",
    "                    c_pairs = list(combinations(docs[1], 2))\n",
    "                    for (a, b) in c_pairs: \n",
    "                        self.candidate_pairs.add((min(a, b), max(a, b)))\n",
    "                        self.taken_candidate_pairs[a][b] = self.taken_candidate_pairs[b][a] = 1\n",
    "            cur_band_end += r\n",
    "            cur_band_start += r\n",
    "\n",
    "    def jaccard_similarity(self, a, b) :\n",
    "        bits = np.bitwise_and(a, b)\n",
    "        dif = np.bitwise_xor(a, b)\n",
    "        return float(np.count_nonzero(bits == 1) / (np.count_nonzero(dif == 1) + np.count_nonzero(bits == 1))) \n",
    "    \n",
    "    def get_similar_documents(self, threshold): \n",
    "        similar_docs = list()\n",
    "        self.similarity_matrix = np.zeros(shape=(len(self.documents), len(self.documents)))\n",
    "        sims = list()\n",
    "\n",
    "        matrixes = [None for _ in range(len(self.documents))]\n",
    "        for i in range(len(self.documents)):\n",
    "            matrixes[i] = self.incident_matrix[:, i]\n",
    "            matrixes[i] = matrixes[i].astype(int)\n",
    "\n",
    "        for doc1 in range(len(self.documents)): \n",
    "            matrix1 = matrixes[doc1]\n",
    "\n",
    "            for doc2 in range(doc1 + 1, len(self.documents)): \n",
    "                matrix2 = matrixes[doc2]\n",
    "            \n",
    "                similarity = self.jaccard_similarity(matrix1, matrix2)\n",
    "                sims.append(similarity)\n",
    "                self.similarity_matrix[doc1][doc2] = self.similarity_matrix[doc2][doc1] = similarity\n",
    "                if similarity >= threshold: \n",
    "                    similar_docs.append((doc1, doc2, similarity))\n",
    "        return list(set(similar_docs)), sims\n",
    "    \n",
    "    def process_candidate_pairs(self, threshold):\n",
    "        false_positive = false_negative = 0\n",
    "        true_positive = true_negative = 0\n",
    "\n",
    "        for doc1 in range(len(self.documents)):\n",
    "            for doc2 in range(doc1 + 1, len(self.documents)):\n",
    "                if self.taken_candidate_pairs[doc1][doc2] == 1:\n",
    "                    if self.similarity_matrix[doc1][doc2] >= threshold:\n",
    "                        true_positive += 1\n",
    "                    else:\n",
    "                        false_positive += 1\n",
    "                elif self.similarity_matrix[doc1][doc2] >= threshold:\n",
    "                    false_negative += 1\n",
    "                else:\n",
    "                    true_negative += 1\n",
    "\n",
    "        print(f'''\n",
    "            true positive count = {true_positive}\n",
    "            true negative count = {true_negative}\n",
    "            false positive count = {false_positive}\n",
    "            false negative count = {false_negative}\n",
    "        ''')\n",
    "        return true_positive, true_negative, false_positive, false_negative \n",
    "\n",
    "    def unpickle(self):\n",
    "        my_path = root / \"Pickled_files\" / \"Incident_Matrix\"\n",
    "        dbfile = open(my_path, 'rb')     \n",
    "        self.incident_matrix = pickle.load(dbfile)\n",
    "        dbfile.close()\n",
    "\n",
    "        my_path = root / \"Pickled_files\" / \"Shingle_id\"\n",
    "        dbfile = open(my_path, 'rb')\n",
    "        self.shingle_id = pickle.load(dbfile)\n",
    "        dbfile.close()\n",
    "\n",
    "        my_path = root / \"Pickled_files\" / \"Shingles\"\n",
    "        dbfile = open(my_path, 'rb')\n",
    "        self.shingles = pickle.load(dbfile)\n",
    "        dbfile.close()\n",
    "\n",
    "        my_path = root / \"Pickled_files\" / \"documents\"\n",
    "        dbfile = open(my_path, 'rb')\n",
    "        self.documents = pickle.load(dbfile)\n",
    "        dbfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_docs(similar_docs):\n",
    "    for x in similar_docs:\n",
    "        print('##############################################################')\n",
    "        print(f'Doc1 is {article_1.title[x[0]]}')\n",
    "        print(f'Doc2 is {article_1.title[x[1]]}')\n",
    "        print(f'Similarity is {x[2] * 100}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### r = 5, b = 10, hash count = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################\n",
      "Doc1 is Transcript: President Obama on What Books Mean to Him - The New York Times\n",
      "Doc2 is Obama’s Secret to Surviving the White House Years: Books - The New York Times\n",
      "Similarity is 65.41832669322709%\n",
      "##############################################################\n",
      "Doc1 is Cyberwar for Sale - The New York Times\n",
      "Doc2 is The Perfect Weapon: How Russian Cyberpower Invaded the U.S. - The New York Times\n",
      "Similarity is 65.01605995717344%\n",
      "##############################################################\n",
      "Doc1 is President Obama’s Farewell Address: Full Video and Text - The New York Times\n",
      "Doc2 is Jolted by Deaths, Obama Found His Voice on Race - The New York Times\n",
      "Similarity is 63.88246946186861%\n",
      "\n",
      "            true positive count = 14\n",
      "            true negative count = 107149\n",
      "            false positive count = 17582\n",
      "            false negative count = 5\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "lsh = LSH(b=10, r=5, hash_cnt=50)\n",
    "similar_docs, sims = lsh.get_similar_documents(0.6)\n",
    "similar_docs.sort(key=lambda x: -x[2])\n",
    "print_docs(similar_docs[:3])\n",
    "true_positive, true_negative, false_positive, false_negative = lsh.process_candidate_pairs(0.6)\n",
    "lsh_stats['b'].append(10)\n",
    "lsh_stats['r'].append(5)\n",
    "lsh_stats['Number of hash functions'].append(50)\n",
    "lsh_stats['True Positive'].append(true_positive)\n",
    "lsh_stats['True Negative'].append(true_negative)\n",
    "lsh_stats['False Positive'].append(false_positive)\n",
    "lsh_stats['False Negative'].append(false_negative)\n",
    "lsh_stats['Candidate Pair count'].append(len(lsh.candidate_pairs))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### r = 5, b = 20, hash count = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################\n",
      "Doc1 is Transcript: President Obama on What Books Mean to Him - The New York Times\n",
      "Doc2 is Obama’s Secret to Surviving the White House Years: Books - The New York Times\n",
      "Similarity is 65.41832669322709%\n",
      "##############################################################\n",
      "Doc1 is Cyberwar for Sale - The New York Times\n",
      "Doc2 is The Perfect Weapon: How Russian Cyberpower Invaded the U.S. - The New York Times\n",
      "Similarity is 65.01605995717344%\n",
      "##############################################################\n",
      "Doc1 is President Obama’s Farewell Address: Full Video and Text - The New York Times\n",
      "Doc2 is Jolted by Deaths, Obama Found His Voice on Race - The New York Times\n",
      "Similarity is 63.88246946186861%\n",
      "\n",
      "            true positive count = 18\n",
      "            true negative count = 82662\n",
      "            false positive count = 42069\n",
      "            false negative count = 1\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "lsh = LSH(b=20, r=5, hash_cnt=100)\n",
    "similar_docs, sims = lsh.get_similar_documents(0.6)\n",
    "similar_docs.sort(key=lambda x: -x[2])\n",
    "print_docs(similar_docs[:3])\n",
    "true_positive, true_negative, false_positive, false_negative = lsh.process_candidate_pairs(0.6)\n",
    "lsh_stats['b'].append(20)\n",
    "lsh_stats['r'].append(5)\n",
    "lsh_stats['Number of hash functions'].append(100)\n",
    "lsh_stats['True Positive'].append(true_positive)\n",
    "lsh_stats['True Negative'].append(true_negative)\n",
    "lsh_stats['False Positive'].append(false_positive)\n",
    "lsh_stats['False Negative'].append(false_negative)\n",
    "lsh_stats['Candidate Pair count'].append(len(lsh.candidate_pairs))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### r = 5, b = 40, hash count = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################\n",
      "Doc1 is Transcript: President Obama on What Books Mean to Him - The New York Times\n",
      "Doc2 is Obama’s Secret to Surviving the White House Years: Books - The New York Times\n",
      "Similarity is 65.41832669322709%\n",
      "##############################################################\n",
      "Doc1 is Cyberwar for Sale - The New York Times\n",
      "Doc2 is The Perfect Weapon: How Russian Cyberpower Invaded the U.S. - The New York Times\n",
      "Similarity is 65.01605995717344%\n",
      "##############################################################\n",
      "Doc1 is President Obama’s Farewell Address: Full Video and Text - The New York Times\n",
      "Doc2 is Jolted by Deaths, Obama Found His Voice on Race - The New York Times\n",
      "Similarity is 63.88246946186861%\n",
      "\n",
      "            true positive count = 18\n",
      "            true negative count = 58597\n",
      "            false positive count = 66134\n",
      "            false negative count = 1\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "lsh = LSH(b=40, r=5, hash_cnt=200)\n",
    "similar_docs, sims = lsh.get_similar_documents(0.6)\n",
    "similar_docs.sort(key=lambda x: -x[2])\n",
    "print_docs(similar_docs[:3])\n",
    "true_positive, true_negative, false_positive, false_negative = lsh.process_candidate_pairs(0.6)\n",
    "lsh_stats['b'].append(40)\n",
    "lsh_stats['r'].append(5)\n",
    "lsh_stats['Number of hash functions'].append(200)\n",
    "lsh_stats['True Positive'].append(true_positive)\n",
    "lsh_stats['True Negative'].append(true_negative)\n",
    "lsh_stats['False Positive'].append(false_positive)\n",
    "lsh_stats['False Negative'].append(false_negative)\n",
    "lsh_stats['Candidate Pair count'].append(len(lsh.candidate_pairs))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### r = 10, b = 20, hash count = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################\n",
      "Doc1 is Transcript: President Obama on What Books Mean to Him - The New York Times\n",
      "Doc2 is Obama’s Secret to Surviving the White House Years: Books - The New York Times\n",
      "Similarity is 65.41832669322709%\n",
      "##############################################################\n",
      "Doc1 is Cyberwar for Sale - The New York Times\n",
      "Doc2 is The Perfect Weapon: How Russian Cyberpower Invaded the U.S. - The New York Times\n",
      "Similarity is 65.01605995717344%\n",
      "##############################################################\n",
      "Doc1 is President Obama’s Farewell Address: Full Video and Text - The New York Times\n",
      "Doc2 is Jolted by Deaths, Obama Found His Voice on Race - The New York Times\n",
      "Similarity is 63.88246946186861%\n",
      "\n",
      "            true positive count = 1\n",
      "            true negative count = 124157\n",
      "            false positive count = 574\n",
      "            false negative count = 18\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "lsh = LSH(b=20, r=10, hash_cnt=200)\n",
    "similar_docs, sims = lsh.get_similar_documents(0.6)\n",
    "similar_docs.sort(key=lambda x: -x[2])\n",
    "print_docs(similar_docs[:3])\n",
    "true_positive, true_negative, false_positive, false_negative = lsh.process_candidate_pairs(0.6)\n",
    "lsh_stats['b'].append(20)\n",
    "lsh_stats['r'].append(10)\n",
    "lsh_stats['Number of hash functions'].append(200)\n",
    "lsh_stats['True Positive'].append(true_positive)\n",
    "lsh_stats['True Negative'].append(true_negative)\n",
    "lsh_stats['False Positive'].append(false_positive)\n",
    "lsh_stats['False Negative'].append(false_negative)\n",
    "lsh_stats['Candidate Pair count'].append(len(lsh.candidate_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>r</th>\n",
       "      <th>Number of hash functions</th>\n",
       "      <th>True Positive</th>\n",
       "      <th>True Negative</th>\n",
       "      <th>False Positive</th>\n",
       "      <th>False Negative</th>\n",
       "      <th>Candidate Pair count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>14</td>\n",
       "      <td>107149</td>\n",
       "      <td>17582</td>\n",
       "      <td>5</td>\n",
       "      <td>17596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>18</td>\n",
       "      <td>82662</td>\n",
       "      <td>42069</td>\n",
       "      <td>1</td>\n",
       "      <td>42087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>18</td>\n",
       "      <td>58597</td>\n",
       "      <td>66134</td>\n",
       "      <td>1</td>\n",
       "      <td>66152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>124157</td>\n",
       "      <td>574</td>\n",
       "      <td>18</td>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    b   r  Number of hash functions  True Positive  True Negative  \\\n",
       "0  10   5                        50             14         107149   \n",
       "1  20   5                       100             18          82662   \n",
       "2  40   5                       200             18          58597   \n",
       "3  20  10                       200              1         124157   \n",
       "\n",
       "   False Positive  False Negative  Candidate Pair count  \n",
       "0           17582               5                 17596  \n",
       "1           42069               1                 42087  \n",
       "2           66134               1                 66152  \n",
       "3             574              18                   575  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(lsh_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
